<?xml version='1.1' encoding='UTF-8'?>
<project>
  <actions/>
  <description>Used to manually update dictionary using Data Dictionary Ingest File Format.&#xd;
Header for datasets.csv: &#xd;
ref	full_name	abbreviation	description {any other metadata columns you want}&#xd;
Header for concepts.csv files (should be zipped - helps with upload/processing speed)&#xd;
dataset_ref	concept name	display name	concept_type	concept_path	parent_concept_path	values	description {any other metadata columns you want}</description>
  <keepDependencies>false</keepDependencies>
  <properties>
    <hudson.model.ParametersDefinitionProperty>
      <parameterDefinitions>
        <hudson.model.FileParameterDefinition>
          <name>datasets.csv</name>
        </hudson.model.FileParameterDefinition>
        <hudson.model.FileParameterDefinition>
          <name>concepts.zip</name>
        </hudson.model.FileParameterDefinition>
        <hudson.model.BooleanParameterDefinition>
          <name>CLEAR_DATABASE</name>
          <defaultValue>false</defaultValue>
        </hudson.model.BooleanParameterDefinition>
      </parameterDefinitions>
    </hudson.model.ParametersDefinitionProperty>
  </properties>
  <scm class="hudson.plugins.git.GitSCM" plugin="git@5.5.2">
    <configVersion>2</configVersion>
    <userRemoteConfigs>
      <hudson.plugins.git.UserRemoteConfig>
        <url>https://github.com/hms-dbmi/picsure-dictionary-etl.git</url>
      </hudson.plugins.git.UserRemoteConfig>
    </userRemoteConfigs>
    <branches>
      <hudson.plugins.git.BranchSpec>
        <name>main</name>
      </hudson.plugins.git.BranchSpec>
    </branches>
    <doGenerateSubmoduleConfigurations>false</doGenerateSubmoduleConfigurations>
    <submoduleCfg class="empty-list"/>
    <extensions/>
  </scm>
  <canRoam>true</canRoam>
  <disabled>false</disabled>
  <blockBuildWhenDownstreamBuilding>false</blockBuildWhenDownstreamBuilding>
  <blockBuildWhenUpstreamBuilding>false</blockBuildWhenUpstreamBuilding>
  <jdk>(System)</jdk>
  <triggers/>
  <concurrentBuild>false</concurrentBuild>
  <builders>
    <hudson.tasks.Shell>
      <command>#!/bin/bash
docker stop dictionaryetl || true
docker rm dictionaryetl || true
docker build -t hms-dbmi/dictionary-etl:gic-sharra -t hms-dbmi/dictionary-etl:latest .

cp /usr/local/docker-config/dictionary/dictionary.env .env

docker stop dictionaryetl || true
docker rm dictionaryetl || true
docker run -d \
  --name dictionaryetl \
  --env-file .env \
  -p 8086:8086 \
  -v $DOCKER_CONFIG_DIR/hpds/:/opt/local/hpds/ \
  --network dictionary \
  --network picsure \
  hms-dbmi/dictionary-etl:latest

echo &quot;Waiting for DictionaryEtlApplication to start...&quot;
MAX_ATTEMPTS=6
SLEEP_INTERVAL=5
ATTEMPT=1

while ! docker logs dictionaryetl 2&gt;&amp;1 | grep -q &quot;Started DictionaryEtlApplication&quot;; do
    if [ &quot;$ATTEMPT&quot; -ge &quot;$MAX_ATTEMPTS&quot; ]; then
        echo &quot;DictionaryEtlApplication failed to start within $((MAX_ATTEMPTS * SLEEP_INTERVAL)) seconds.&quot;
        docker logs dictionaryetl
        docker stop dictionaryetl
        docker rm dictionaryetl
        exit 1
    fi
    echo &quot;Attempt $ATTEMPT: Application not started yet. Retrying in $SLEEP_INTERVAL seconds...&quot;
    sleep $SLEEP_INTERVAL
    ATTEMPT=$((ATTEMPT + 1))
done

echo &quot;DictionaryEtlApplication has started!&quot;

if [ &quot;$CLEAR_DATABASE&quot; ]; then
	echo &quot;Clearing database&quot;
	curl http://dictionaryetl:8086/load/clear
else
	echo &quot;Not clearing DB&quot;
fi
echo &quot;Adding datasets&quot;
curl -X PUT -T datasets.csv http://dictionaryetl:8086/api/dataset/csv

echo &quot;Extracting concepts&quot;
mkdir concepts
unzip concepts.zip -d concepts

IFS=&apos;,&apos;      
while read ref fullname abv desc
do
if [[ $ref != *&apos;ref&apos;* ]]; then
	dataset=`echo ${ref} | tr -d &apos;&quot;&apos;`
    mkdir $dataset
	echo &quot;Fetching concepts for $dataset&quot;
	head -n 1 concepts/concepts_0.csv &gt; ${dataset}/concepts.csv
    grep -h -e &quot;^\&quot;*$dataset&quot; concepts/concepts* &gt;&gt; ${dataset}/concepts.csv
	encoded_dataset=$(printf &quot;$dataset&quot; | sed &apos;s/ /%20/g&apos;)
    echo &quot;Building concepts for $dataset&quot;
    if [[  $(wc -l &lt; ${dataset}/concepts.csv) -gt 50000 ]];
    then
    	{
          echo &apos;large dataset - splitting files to prevent oom&apos;
          i=1
          line1=2
          while [[ $line1 -lt $(wc -l &lt; ${dataset}/concepts.csv) ]];
              do
                  line2=$(($line1+50000))
                   
                  if [[ $line2 -gt $(wc -l &lt; ${dataset}/concepts.csv) ]]; then
                      line2=`wc -l &lt; ${dataset}/concepts.csv`
                  fi
                  echo &quot;started $dataset line1 $line1 through line2 $line2&quot;
                 
                    head -n 1 ${dataset}/concepts.csv &gt; ${dataset}/concepts_$i.csv
                    sed -n &quot;${line1},${line2}p&quot; ${dataset}/concepts.csv &gt;&gt; ${dataset}/concepts_$i.csv
                    curl --request PUT --header &apos;Content-Type: text/plain&apos; \
                        --data-binary @${dataset}/concepts_$i.csv \
                        &quot;http://dictionaryetl:8086/api/concept/csv?datasetRef=${encoded_dataset}&quot;
                        
                    echo &quot;completed $dataset line1 $line1 through line2 $line2&quot;
                  
                  i=$(($i+1))
                  line1=$line2
              done
          } &amp;
    else
	{
      echo started $dataset ingest
      curl --request PUT --header &apos;Content-Type: text/plain&apos; \
        --data-binary @${dataset}/concepts.csv \
        &quot;http://dictionaryetl:8086/api/concept/csv?datasetRef=${encoded_dataset}&quot;
      echo completed $dataset ingest
    } &amp;
    fi
else
	echo &quot;skipping header line&quot;
fi
done &lt; datasets.csv
wait;
echo Completed all dataset updates, refreshing base facets

#curl --fail --no-progress-meter --request PUT --header &apos;Content-Type: text/plain&apos; \
#      http://dictionaryetl:8086/api/facet/general/refresh/ &amp;&amp; echo completed facet refresh

docker exec -i dictionary-db psql dictionary picsure -c &apos;UPDATE dict.update_info SET last_updated = NOW();&apos;
</command>
      <configuredLocalRules/>
    </hudson.tasks.Shell>
  </builders>
  <publishers/>
  <buildWrappers>
    <hudson.plugins.ws__cleanup.PreBuildCleanup plugin="ws-cleanup@0.47">
      <deleteDirs>false</deleteDirs>
      <cleanupParameter></cleanupParameter>
      <externalDelete></externalDelete>
      <disableDeferredWipeout>false</disableDeferredWipeout>
    </hudson.plugins.ws__cleanup.PreBuildCleanup>
  </buildWrappers>
</project>