<?xml version='1.1' encoding='UTF-8'?>
<project>
  <actions/>
  <description>Load HPDS Data from CSV using the Jenkins job - &quot;Load HPDS Data From CSV&quot; &#xd;
&#xd;
This job requires datafile in csv format in location - /usr/local/docker-config/hpds_csv/allConcepts.csv&#xd;
&#xd;
Expects listed data format and header :&#xd;
&#xd;
&quot;PATIENT_NUM&quot;,&quot;CONCEPT_PATH&quot;,&quot;NVAL_NUM&quot;,&quot;TVAL_CHAR&quot;,&quot;TIMESTAMP&quot;&#xd;
&#xd;
PLEASE Note : The data in CSV has to be sorted by CONCEPT_PATH,PATIENT_NUM,TIMESTAMP.&#xd;
&#xd;
The corresponding columns from the CSV file are:&#xd;
&#xd;
PATIENT_NUM: This is an integer value identifying the subject of the recorded observation fact.&#xd;
&#xd;
CONCEPT_PATH: This is an identifier for the concept of the observation fact. For compatibility with the PIC-SURE UI this path should represent a location in a hierarchy where each level is separated by a backslash and with a leading and trailing backslash. For example &quot;\demographics\AGE&quot; would be the age in the default NHANES dataset. In general this can be any string value, so the UI will display whatever is inside HPDS. If this HPDS instance is part of a PIC-SURE networked environment the same concept paths should be used in all sites involved in the network so that queries can be federated across the network.
If the concept path has the TVAL_CHAR in it, HPDS reads the concept path as including the TVAL_CHAR. Therefore, you have three options to loading the data, as shown below:
Options | PATIENT_NUM | CONCEPT_PATH | NVAL_NUM | TVAL_CHAR | TIMESTAMP
:--- | :--- | :--- | :--- | :--- | :--- 
Option 1 | 1530172 | \Consent Type\Waiver of consent\ | NULL | Yes | 1.6149E+12
Option 2 | 1530172 | \Consent Type\Waiver of consent\Yes | NULL | Yes | 1.6149E+12
Option 3 | 1530172 | \Consent Type\Waiver of consent\Yes\ | NULL | Yes | 1.6149E+12    &#xd;
&#xd;
NVAL_NUM: A numeric value if this is a numeric concept, otherwise blank.&#xd;
&#xd;
TVAL_CHAR: A text value if this is a categorical concept, otherwise blank. TVAL-CHAR is case-sensitive.&#xd;
&#xd;
TIMESTAMP: A timestamp for the observation fact, this should be expressed as the number of milliseconds since January 1, 1970 GMT. &#xd;
This is equivalent to the Unix Epoch time value for the time of the observation multiplied by 1000.&#xd;
&#xd;
&#xd;
1. Run Jenkins job - Load HPDS Data From CSV&#xd;
&#xd;
Check the console output of the run make sure it completed successfully.&#xd;
&#xd;
2. Run Jenkins job - Start PIC-SURE&#xd;
&#xd;
Check the console output of the run make sure it completed successfully.&#xd;
&#xd;
This Job extracts the new .bin files, deploys the new data into the live folder.&#xd;
It also backs-up the previous data in backup folder, only one previous backup is kept.&#xd;
</description>
  <keepDependencies>false</keepDependencies>
  <properties/>
  <scm class="hudson.scm.NullSCM"/>
  <canRoam>true</canRoam>
  <disabled>false</disabled>
  <blockBuildWhenDownstreamBuilding>false</blockBuildWhenDownstreamBuilding>
  <blockBuildWhenUpstreamBuilding>false</blockBuildWhenUpstreamBuilding>
  <triggers/>
  <concurrentBuild>false</concurrentBuild>
  <builders>
    <hudson.tasks.Shell>
      <command>

rm -rf /usr/local/docker-config/hpds_temp
rm -rf /usr/local/docker-config/hpds_pheno_bak
mkdir -p /usr/local/docker-config/hpds_temp

docker stop hpds-etl &amp;&amp; docker rm hpds-etl

#generate a new encryption key
openssl enc -aes-128-cbc -k secret -P | grep key | cut -d &apos;=&apos; -f2 &gt;  /usr/local/docker-config/hpds_temp/encryption_key

docker stop hpds_data_load_csv &amp;&amp; docker rm hpds_data_load_csv
docker run --name=hpds-etl \
  -v /usr/local/docker-config/hpds_temp:/opt/local/hpds \
  -v /usr/local/docker-config/hpds_csv/allConcepts.csv:/opt/local/hpds/allConcepts.csv \
  -e HEAPSIZE=4096 -e LOADER_NAME=CSVLoader \
  --name hpds_data_load_csv hms-dbmi/pic-sure-hpds-etl:LATEST &amp;&amp; \
find /usr/local/docker-config/hpds/ -not -type d -maxdepth 1 -exec echo mv {} /usr/local/docker-config/hpds_pheno_bak \;    &amp;&amp; \
mv /usr/local/docker-config/hpds_temp/* /usr/local/docker-config/hpds
</command>
    </hudson.tasks.Shell>
  </builders>
  <publishers/>
  <buildWrappers/>
</project>
